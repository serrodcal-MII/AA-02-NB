{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos probabilísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los ejemplos y la discusión que sigue está parcialmente tomado del libro:\n",
    "\n",
    "[*Introduction to Machine Learning with Python*](http://shop.oreilly.com/product/0636920030515.do)  \n",
    "**Andreas C. Müller & Sarah Guido**  \n",
    "O'Reilly 2017\n",
    "\n",
    "En concreto, este tema está basado en el capítulo 7, pero con modificaciones. \n",
    "\n",
    "Github con el material del libro: [Github](https://github.com/amueller/introduction_to_ml_with_python). \n",
    "\n",
    "El libro está accesible *online* desde la [Biblioteca de la Universidad de Sevilla](https://fama.us.es), como recurso electrónico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación: clasificación de textos usando Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando el conjunto de entrenamiento: críticas de película en IMDB \n",
    "\n",
    "Como datos en nuestra aplicación usaremos críiticas de películas en la web IMDB (Internet Movie Database). Son críticas que ya vienen con la etiqueta \"pos\" o \"neg\", de acuerdo a la puntuación que acompaña a la crítica (positiva, 7 o más; negativa 4 o menos). El objetivo es ser capaz de declarar como positiva o negativa una crítica (por supuesto, sin saber la puntuación que la acompaña).\n",
    "\n",
    "Los datos están disponibles en [http://ai.stanford.edu/~amaas/data/sentiment/](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "Descargar el archivo comprimido con los datos, y descomprimir, quedando la siguiente estructura: \n",
    "\n",
    "```\n",
    "data/\n",
    "└── aclImdb/\n",
    "    ├── test/\n",
    "    │   ├── neg\n",
    "    │   └── pos\n",
    "    └── train/\n",
    "        ├── neg\n",
    "        └── pos\n",
    "```\n",
    "     \n",
    "Nota: de aquí hemos eliminado la carpete `train/unsup`, que no usaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `load_files` que viene en el módulo `datasets` de scikit-learn permite cargar conjuntos de datos que vienen en carpetas con esa estructura. Cargamos el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = load_files(\"data/aclImdb/train/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, y_train = reviews_train.data, reviews_train.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de text_train: <class 'list'>\n",
      "Tipo de y_train: <class 'numpy.ndarray'>\n",
      "Cantidad de textos en el conjunto de entrenamiento: 25000\n",
      "Etiquetas: ['neg', 'pos']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tipo de text_train: {}\".format(type(text_train)))\n",
    "print(\"Tipo de y_train: {}\".format(type(y_train)))\n",
    "print(\"Cantidad de textos en el conjunto de entrenamiento: {}\".format(len(text_train)))\n",
    "print(\"Etiquetas: {}\".format(reviews_train.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos ejemplo de estas revisiones que acabamos de cargar. Téngase en cuenta que los valores de clasificación son 0 y 1, correspondiendo a \"neg\" y \"pos\", resp.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_train[6]:\n",
      "b\"This movie has a special way of telling the story, at first i found it rather odd as it jumped through time and I had no idea whats happening.<br /><br />Anyway the story line was although simple, but still very real and touching. You met someone the first time, you fell in love completely, but broke up at last and promoted a deadly agony. Who hasn't go through this? but we will never forget this kind of pain in our life. <br /><br />I would say i am rather touched as two actor has shown great performance in showing the love between the characters. I just wish that the story could be a happy ending.\"\n",
      "\n",
      "y_train[6]: 1\n",
      "\n",
      "Etiqueta asociada: pos\n"
     ]
    }
   ],
   "source": [
    "print(\"text_train[6]:\\n{}\\n\".format(text_train[6]))\n",
    "print(\"y_train[6]: {}\\n\".format(y_train[6]))\n",
    "print(\"Etiqueta asociada: {}\".format(reviews_train.target_names[y_train[6]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_train[25]:\n",
      "b\"A chemical spill is turning people into zombies. It's up to two doctor's to survive the epidemic. It's an Andreas Schnaas film so you know what the par for the course will be. Bad acting, horribly awful special effects, and no budget to speak of. The dubbing is ridiculous with a capital R and the saddest thing is that I feel compelled to write one word about this piece of excrement, much less the ten lines mandatory because of the guidelines placed on me by IMDb. My original review of merely one word: Crap wouldn't fly so I have to revise it and go more in to how bad it is. But I don't know if I can, so.. wait I think I may have enough words, or lines rather to make this review pass. Which is cool, I guess. So in summation: This movie sucks balls, don't watch it.<br /><br />My Grade: F\"\n",
      "\n",
      "y_train[25]: 0\n",
      "\n",
      "Etiqueta asociada: neg\n"
     ]
    }
   ],
   "source": [
    "print(\"text_train[25]:\\n{}\\n\".format(text_train[25]))\n",
    "print(\"y_train[25]: {}\\n\".format(y_train[25]))\n",
    "print(\"Etiqueta asociada: {}\".format(reviews_train.target_names[y_train[25]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se observa en los ejemplos anteriores, en los textos hay muchas etiquetas de cambio de línea en HTML, que obviamente no tienen impacto en el sentimiento que expresa el texto, así que las quitamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trata además de un conjunto de datos balanceado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplos por cada clase: [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Ejemplos por cada clase: {}\".format(np.bincount(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos de la msma manera el conjunto de test, que tiene exactamente el mismo número de ejemplos, e igualmente balanceados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_test = load_files(\"data/aclImdb/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test, y_test = reviews_test.data, reviews_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos en test: 25000\n",
      "Ejemplos por cada clase: [12500 12500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de ejemplos en test: {}\".format(len(text_test)))\n",
    "print(\"Ejemplos por cada clase: {}\".format(np.bincount(y_test)))\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El modelo vectorial *Bag of Words*\n",
    "\n",
    "Antes de poder aplicar modelos de aprendizaje a textos, debemos representar los documentos mediante vectores numéricos. Como hemos visto en el desarrollo del tema, la forma más fácil de hacerlo es, una vez fijado los términos de nuestro *Vocabulario* (y un orden implícito entre los términos), mediante un vector en el que en cada componente tenemos el número de veces que aparece el correspondiente término del vocabulario, en el documento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un ejemplo de juguete sobre la vectorización:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El transformador `CountVectorizer` hace posible esta representación vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `fit` del vectorizador básicamente recopila el vocabulario, recibiendo como entrada una lista de strings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del vocabulario: 13\n",
      "Vocabulario:\n",
      " {'the': 9, 'fool': 3, 'doth': 2, 'think': 10, 'he': 4, 'is': 6, 'wise': 12, 'but': 1, 'man': 8, 'knows': 7, 'himself': 5, 'to': 11, 'be': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del vocabulario: {}\".format(len(vect.vocabulary_)))\n",
    "print(\"Vocabulario:\\n {}\".format(vect.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `transform`del vectorizador transforma los documentos en vectores. Puesto que la mayoría de las componentes son cero (todos los términos del vocabulario que **no** están en el documento), la representación más adecuada es mediante *matrices dispersas* de **Scipy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag_of_words: <2x13 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 16 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "print(\"bag_of_words: {}\".format(repr(bag_of_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo pequeño, podemos ver los arrays no dispersos que equivalen a esta representación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representación no dispersa de los documentos del ejemplo:\n",
      "[[0 0 1 1 1 0 1 0 0 1 1 0 1]\n",
      " [1 1 0 1 0 1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Representación no dispersa de los documentos del ejemplo:\\n{}\".format(\n",
    "    bag_of_words.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-word para las críticas de cine\n",
    "\n",
    "Aplicamos una transformación equivalente a nuestro caso de las críticas de películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer().fit(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:\n",
      "<25000x74849 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3431196 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "X_train = vect.transform(text_train)\n",
    "print(\"X_train:\\n{}\".format(repr(X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploremos un poco el vocabulario que se ha recopilado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario: 74849\n",
      "Primeras 20 características (términos):\n",
      "['00', '000', '0000000000001', '00001', '00015', '000s', '001', '003830', '006', '007', '0079', '0080', '0083', '0093638', '00am', '00pm', '00s', '01', '01pm', '02']\n",
      "Términos del 20010 al 20030:\n",
      "['dratted', 'draub', 'draught', 'draughts', 'draughtswoman', 'draw', 'drawback', 'drawbacks', 'drawer', 'drawers', 'drawing', 'drawings', 'drawl', 'drawled', 'drawling', 'drawn', 'draws', 'draza', 'dre', 'drea']\n",
      "Términos cada 2000 posiciones:\n",
      "['00', 'aesir', 'aquarian', 'barking', 'blustering', 'bête', 'chicanery', 'condensing', 'cunning', 'detox', 'draper', 'enshrined', 'favorit', 'freezer', 'goldman', 'hasan', 'huitieme', 'intelligible', 'kantrowitz', 'lawful', 'maars', 'megalunged', 'mostey', 'norrland', 'padilla', 'pincher', 'promisingly', 'receptionist', 'rivals', 'schnaas', 'shunning', 'sparse', 'subset', 'temptations', 'treatises', 'unproven', 'walkman', 'xylophonist']\n"
     ]
    }
   ],
   "source": [
    "feature_names = vect.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario: {}\".format(len(feature_names)))\n",
    "print(\"Primeras 20 características (términos):\\n{}\".format(feature_names[:20]))\n",
    "print(\"Términos del 20010 al 20030:\\n{}\".format(feature_names[20010:20030]))\n",
    "print(\"Términos cada 2000 posiciones:\\n{}\".format(feature_names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion textos usando Naive Bayes Multinomial\n",
    "\n",
    "Una vez que ya hemos visto cómo vectorizar los documentos, ya podemos aplicar el clasificador `MultinomialNB` para obtener predicciones sobre el \"sentimiento\" de una crítica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Regresión logística con el parámetro por defecto\n",
    "multinb=MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basicamente, lo que se ha hecho al entrenar el modelo, es contar términos por cada clase, y calcular el logaritmo de las proporciones. Esto lo podemos consultar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12500. 12500.]\n",
      "[-0.69314718 -0.69314718]\n",
      "[[ 51. 174.   1. ...   0.   3.   1.]\n",
      " [ 42. 126.   0. ...   1.   1.   0.]]\n",
      "[[-10.90247427  -9.68893202 -14.16057081 ... -14.85371799 -13.46742363\n",
      "  -14.16057081]\n",
      " [-11.11979709 -10.03681011 -14.8809972  ... -14.18785002 -14.18785002\n",
      "  -14.8809972 ]]\n"
     ]
    }
   ],
   "source": [
    "print(multinb.class_count_)\n",
    "print(multinb.class_log_prior_)\n",
    "print(multinb.feature_count_)\n",
    "print(multinb.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo se comporta el modelo entrenado en la clasificación de un par de documentos del test. En concreto en la crítica segunda y tercera. La segunda del test es una crítica negativa, y la tercera es positiva:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segunda crítica del conjunto de test: \n",
      "\n",
      "b'I don\\'t know how this movie has received so many positive comments. One can call it \"artistic\" and \"beautifully filmed\", but those things don\\'t make up for the empty plot that was filled with sexual innuendos. I wish I had not wasted my time to watch this movie. Rather than being biographical, it was a poor excuse for promoting strange and lewd behavior. It was just another Hollywood attempt to convince us that that kind of life is normal and OK. From the very beginning I asked my self what was the point of this movie,and I continued watching, hoping that it would change and was quite disappointed that it continued in the same vein. I am so glad I did not spend the money to see this in a theater!'\n",
      "\n",
      "Clasificación verdadera: 0.\n",
      "\n",
      "\n",
      "Tercera crítica del conjunto de test: \n",
      "\n",
      "b\"I caught this movie on the Horror Channel and was quite impressed by the film's Gothic atmosphere and tone. As a big fan of all things vampire related, I am always happy to see a new variation of the vampire mythos, in this case, a ghoul-like creature residing in a Lovecraftian other dimension. The director has done a brilliant job of conveying the dark mood of the subject, using the decadent art scene as a backdrop to what is essentially a tale of love spanning time and space- the pure love of friendship opposed to the lust for blood and life by the vampires in the story. The characters in the story are transported to another dimension by the means of a mind-altering substance, where a shape-shifting vampire creature appears to grant them their hearts desires, whilst draining them of their life essence. There are some analogies to drug addiction and loss of control, and how this affects a group of friends in an artistic circle. I enjoyed watching the 2 main male characters in the story, Chris Ivan Cevic and Alex Petrovich, who were very attractive hunks, always a plus point in a vampire story for the female viewers! The special effects make up and creature effects were well done, and the set design of the vampire's dimension was very effective. All in all, an enjoyable take on vampire myths, and recommended for anyone who likes their vampires with some intelligence and not just action. The only thing missing to make it even better would have been a bit more eroticism and nudity, as it would have suited the plot and themes.\"\n",
      "\n",
      "Clasificación verdadera: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Segunda crítica del conjunto de test: \\n\\n{}\\n\".format(text_test[1]))\n",
    "print(\"Clasificación verdadera: {}.\\n\\n\".format(y_test[1]))\n",
    "\n",
    "print(\"Tercera crítica del conjunto de test: \\n\\n{}\\n\".format(text_test[2]))\n",
    "print(\"Clasificación verdadera: {}\".format(y_test[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos cómo los clasifica nuestro clasificador `multinb`. Para ello, primero tenemos que transformarlos a vectores, y luego aplicar la predicción con clasificador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción del clasificador para la segunda crítica: 0\n",
      "\n",
      "Predicción del clasificador para la tercera crítica: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicción del clasificador para la segunda crítica: {}\\n\".format(multinb.predict(vect.transform([text_test[1]]))[0]))\n",
    "\n",
    "print(\"Predicción del clasificador para la tercera crítica: {}\".format(multinb.predict(vect.transform([text_test[2]]))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Perfecto!, el clasificador ha sido capaz de acertar qué tipo de críticas eran. Con `predict_proba`, podemos saber cómo de seguro estaba de su predicción. Como se ve, estaba bastante seguro en ambos casos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción de probabilidad para la segunda crítica: [9.99999862e-01 1.37575474e-07]\n",
      "\n",
      "Predicción de probabilidad para la tercera crítica: [0.01977596 0.98022404]\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicción de probabilidad para la segunda crítica: {}\\n\".format(multinb.predict_proba(vect.transform([text_test[1]]))[0]))\n",
    "\n",
    "print(\"Predicción de probabilidad para la tercera crítica: {}\".format(multinb.predict_proba(vect.transform([text_test[2]]))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin embargo, no necesariamente acierta en todas las revisiones. Por ejemplo, la primera crítica es positiva y el clasificador la clasifica como negativa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primera crítica del conjunto de test: \n",
      "\n",
      "b\"Don't hate Heather Graham because she's beautiful, hate her because she's fun to watch in this movie. Like the hip clothing and funky surroundings, the actors in this flick work well together. Casey Affleck is hysterical and Heather Graham literally lights up the screen. The minor characters - Goran Visnjic {sigh} and Patricia Velazquez are as TALENTED as they are gorgeous. Congratulations Miramax & Director Lisa Krueger!\"\n",
      "\n",
      "Clasificación verdadera: 1.\n",
      "\n",
      "Predicción del clasificador para la primera crítica: 0\n",
      "\n",
      "Predicción de probabilidad para la primera crítica: [0.68716538 0.31283462]\n"
     ]
    }
   ],
   "source": [
    "print(\"Primera crítica del conjunto de test: \\n\\n{}\\n\".format(text_test[0]))\n",
    "print(\"Clasificación verdadera: {}.\\n\".format(y_test[0]))\n",
    "\n",
    "print(\"Predicción del clasificador para la primera crítica: {}\\n\".format(multinb.predict(vect.transform([text_test[0]]))[0]))\n",
    "\n",
    "print(\"Predicción de probabilidad para la primera crítica: {}\".format(multinb.predict_proba(vect.transform([text_test[0]]))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "Veamos el **rendimiento global** del clasificador **sobre los conjuntos de entrenamiento y test**, que no está nada mal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de multinb sobre el conjunto de entrenamiento: 0.90\n",
      "Rendimiento de multinb sobre el conjunto de test: 0.81\n"
     ]
    }
   ],
   "source": [
    "X_test = vect.transform(text_test)\n",
    "print(\"Rendimiento de multinb sobre el conjunto de entrenamiento: {:.2f}\".format(multinb.score(X_train,y_train)))\n",
    "print(\"Rendimiento de multinb sobre el conjunto de test: {:.2f}\".format(multinb.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por defecto, el parámeto de suavizado `alpha` es 1.0. Podemos usar probar con distintos valores de suavizado (cambiando la cantidad de regularización), a ver qué pasa. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de multinb sobre el conjunto de entrenamiento 0.87\n",
      "Rendimiento de multinb sobre el conjunto de test: 0.82\n"
     ]
    }
   ],
   "source": [
    "multinb_alpha=MultinomialNB(alpha=10).fit(X_train,y_train)\n",
    "print(\"Rendimiento de multinb sobre el conjunto de entrenamiento {:.2f}\".format(multinb_alpha.score(X_train,y_train)))\n",
    "print(\"Rendimiento de multinb sobre el conjunto de test: {:.2f}\".format(multinb_alpha.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante ver qué ocurre cuando se van cambiando los distintos valores de `alpha` (¿por qué?) (¿cómo influye `alpha` en la regularización?). Para ello podemos usar validación cruzada sobre el conjunto de entrenamiento, y decidir con eso cuál es el mejor `alpha` de un conjunto de candidatos. La utilidad `GridSearchCV` nos automatiza todo el proceso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor parámetro:  {'alpha': 0.1}\n",
      "Rendimiento de MultonomialNB en validación cruzada, con el mejor parámetro: 0.85\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_nb = {'alpha': [0.0001,0.001, 0.01,0.1, 1, 10,100,200]}\n",
    "grid_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5)\n",
    "grid_nb.fit(X_train, y_train)\n",
    "print(\"Mejor parámetro: \", grid_nb.best_params_)\n",
    "print(\"Rendimiento de MultonomialNB en validación cruzada, con el mejor parámetro: {:.2f}\".format(grid_nb.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De entre los `alpha` candidatos, se ha encontrado que el mejor es el que corresponde al valor de suavizado 0.1. Hay que recordar que `GridSearchCV` es en sí mismo un clasificador, que al entrenarse (`fit`) queda con el clasificador que resulta de usar el mejor de todos los parámetros. Y también tenemos métodos `predict`, `predict`, `predict_proba` y `score`. \n",
    "\n",
    "Para dar una evaluación final, miramos la tasa de aciertos sobre el conjunto de prueba. Como se observa no necesariamente es mejor que el mejor rendimiento de los parámetos del grid sobre el conjunto de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento sobre prueba (del mejor parámetro en validación cruzada): 0.80\n"
     ]
    }
   ],
   "source": [
    "print(\"Rendimiento sobre prueba (del mejor parámetro en validación cruzada): {:.2f}\".format(grid_nb.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorando la vectorización: *stop words*, `min_df`\n",
    "\n",
    "Los *stop words* son palabras de uso tan frecuente que no aportan nada a la clasificación de textos (ya que no dan información sobre la clase a la que se pertenece). Igualmente, aquellos términos de muy baja frecuencia podrían ignorarse y así ganar en eficiencia (se tendrían menos características). Las opciones `min_df` y `stop_words` del vectorizador nos permiten llevar a cabo esto: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect2 = CountVectorizer(min_df=100, stop_words=\"english\").fit(text_train)\n",
    "X2_train = vect2.transform(text_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsérvese como se reduce drásticamente el número de características:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de términos en el vocabulario original: 74849\n",
      "Número de términos en el vocabulario con stop words y min_df: 3561\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de términos en el vocabulario original: {}\".format(len(feature_names)))\n",
    "feature_names2 = vect2.get_feature_names()\n",
    "print(\"Número de términos en el vocabulario con stop words y min_df: {}\".format(len(feature_names2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtengamos un clasificador para esta nueva vectorización, y vemos cómo sube (algo) el rendimiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinb2=MultinomialNB(alpha=0.1).fit(X2_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de multinb2 sobre el conjunto de entrenamiento 0.85\n",
      "Rendimiento de multinb2 sobre el conjunto de test: 0.84\n"
     ]
    }
   ],
   "source": [
    "X2_test = vect2.transform(text_test)\n",
    "\n",
    "print(\"Rendimiento de multinb2 sobre el conjunto de entrenamiento {:.2f}\".format(multinb2.score(X2_train,y_train)))\n",
    "print(\"Rendimiento de multinb2 sobre el conjunto de test: {:.2f}\".format(multinb2.score(X2_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos ahora un tratamiento ahora con `GridSearchCV`, similar a lo que hemos hecho, pero con esta nueva vectorización. Hay que señalar que podría ser posible buscar también valores buenos para los parámetros `min_df` y alguno más de la vectorización, pero para eso deberíamos haber visto antes los *pipelines* de scikit learn. Nos conformamos de momentos con buscar un valor para `alpha`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor parámetro:  {'alpha': 0.0001}\n",
      "Rendimiento de MultonomialNB (con min_df y stop words) en validación cruzada, con el mejor parámetro: 0.84\n",
      "Rendimiento sobre prueba (del mejor parámetro en validación cruzada): 0.84\n"
     ]
    }
   ],
   "source": [
    "grid2_nb = GridSearchCV(MultinomialNB(), param_grid_nb, cv=5)\n",
    "grid2_nb.fit(X2_train, y_train)\n",
    "print(\"Mejor parámetro: \", grid2_nb.best_params_)\n",
    "print(\"Rendimiento de MultonomialNB (con min_df y stop words) en validación cruzada, con el mejor parámetro: {:.2f}\".format(grid2_nb.best_score_))\n",
    "print(\"Rendimiento sobre prueba (del mejor parámetro en validación cruzada): {:.2f}\".format(grid2_nb.score(X2_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
